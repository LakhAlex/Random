from playwright.sync_api import sync_playwright
import time
from bs4 import BeautifulSoup
import re
import csv

class webScrap:
    def __init__(self, keyWord):
        self.keyword = keyWord
        self.all_jobs = []


    def keywordJob(self):  # ì „ë‹¬ë°›ì€ keywordë¥¼ ì‚¬ìš©í•´ì„œ í˜ì´ì§€ ë‚´ë¶€ì˜ ë‚´ìš©ì„ ì €ì¥í•˜ê¸°

        print(f"{self.keyword} page scraping start!")

        # ë™ì ìœ¼ë¡œ ì½ì–´ì•¼ ì½íˆëŠ” ìƒí™©
        p = sync_playwright().start()  # playwright ì‹œì‘!

        browser = p.chromium.launch() # ë¸Œë¼ìš°ì € : í¬ë¡¬

        page = browser.new_page() # ë¸Œë¼ìš°ì €ì— ìƒˆë¡œìš´ íƒ­ ìƒì„±

        page.goto(f"https://remoteok.com/remote-{self.keyword}-jobs") # keywordsì— ìˆëŠ” ì§ì—…ì„ ê²€ìƒ‰!

        time.sleep(3) # í™”ë©´ ë¡œë”© ëŒ€ê¸°

        # ìŠ¤í¬ë¡¤ì„ ë”ì´ìƒ ë‚´ë¦´ ìˆ˜ ì—†ì„ ë•Œê¹Œì§€ ë‚´ë¦¬ëŠ” ì½”ë“œë„ ì§œë´¤ëŠ”ë°, pythonì´ë‚˜ golangì´ ê²½ìš° 1ë…„ ì´ìƒ ì§€ë‚œ ê²Œì‹œë¬¼ê¹Œì§€ ì „ë¶€ ë¡œë”©ë˜ëŠ”ê±¸ í™•ì¸í•˜ê³  ì•„ë˜ ì½”ë“œë¡œ ìµœì¢… ê²°ì •.
        for i in range(4): # ìŠ¤í¬ë¡¤ 4ë²ˆë§Œ ë‚´ë¦¬ë©´ ë‚´ ì»´í“¨í„° ê¸°ì¤€ 120ê°œ ì •ë„ì˜ ê²Œì‹œë¬¼ì´ ë¡œë”©ë¨.
            page.keyboard.down('End')
            time.sleep(5)

        content = page.content()  # í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        browser.close()
        p.stop()
        
        self.content = content
        print(f"{self.keyword} page scraping finish!")


    def beautiSoup(self):  # beautifulSoupë¥¼ ì‚¬ìš©í•´ì„œ ì›í•˜ëŠ” ë°ì´í„°ë¥¼ ë½‘ì•„ë‚´ê¸°

        print(f"{self.keyword} job list making...") # í˜„ì¬ ìŠ¤í¬ë© ì¤‘ì¸ ì¡ì„ ì•Œë ¤ì¤Œ

        soup = BeautifulSoup(self.content, "html.parser")

        jobsboard = soup.find('table', id='jobsboard'
                        ).find_all('td', class_='company position company_and_position')[1:]

        for job in jobsboard:
            link = f"https://remoteok.com{job.find('a')['href']}"  # ê°ê° ì§ì—…ì— ê±¸ë ¤ì ¸ìˆëŠ” ë§í¬ì™„ì„±í•˜ê¸°!
            title = job.find("h2", itemprop="title").text.strip()  # ì œëª©
            company = job.find("h3", itemprop="name").text.strip()  # íšŒì‚¬

            location_check = job.find('div', class_='location') # ì´ë ‡ê²Œë§Œ ê°€ì ¸ì˜¤ë©´ location_tooltip, location_tooltip-set ê¹Œì§€ ê°™ì´ ê°€ì ¸ì˜¤ì§.
            if location_check is None: # ë‚´ìš©ì´ ì—†ì–´ì„œ None ìœ¼ë¡œ ë¶ˆëŸ¬ì™€ì§„ ê²½ìš° í¸ì§‘
                location='ì •ë³´ ì—†ìŒ'
            elif 'tooltip' in location_check.get('class', []):  # 'tooltip'ì´ class ì†ì„±ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ í›„ í¸ì§‘
                location='ì •ë³´ ì—†ìŒ'
            elif 'tooltip-set' in location_check.get('class', []):  # 'tooltip-set'ì´ class ì†ì„±ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ í›„ í¸ì§‘
                location='ì •ë³´ ì—†ìŒ'
            else:
                location=location_check.text.strip()

            pay = job.find("div", class_="location tooltip", title=re.compile("No salary data published"))

            if pay:
                pay = pay.get_text(strip=True)  # í…ìŠ¤íŠ¸ë§Œ ê°€ì ¸ì˜¤ê³  ì–‘ìª½ ê³µë°±ì„ ì œê±°
                # print(pay)  # ğŸ’° $60k - $130k*
            else:
                pay = "None"  # ê°’ì´ ì—†ì„ ê²½ìš°!

            job = {
                "title" : title,
                "company" : company,
                "location" : location,
                "pay" : pay,
                "link" : link
            }

            self.all_jobs.append(job)  # ìƒì„±ëœ job ë”•ì…”ë„ˆë¦¬ë¥¼ all_jobs ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€!


        file = open(f"{self.keyword}.csv", "w", encoding="utf-8")
        writter = csv.writer(file)

        writter.writerow([
            "Ttile",
            "Company",
            "Location",
            "Pay",
            "Link"
        ])

        for job in self.all_jobs:  # ì½ì€ ì •ë³´ë¥¼ ì´ì œ csv íŒŒì¼ì— ì“°ê¸°!
            writter.writerow(job.values())
        file.close()  # ë‹¤ ì¼ìœ¼ë©´ file ë‹«ê¸°

        print(f'{self.keyword} job list making finish.') # ì§„í–‰ìƒí™© ë¸Œë¦¬í•‘
        print(f'ì •ë¦¬ëœ {self.keyword} job ìˆ˜ëŠ” {len(self.all_jobs)} ì…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ csv íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.') # ê²°ê³¼ í™•ì¸ìš© ë©”ì‹œì§€
    

# ìš°ë¦¬ê°€ ì´ì œ ê²€ìƒ‰í•˜ê³ ì í•˜ëŠ” ì§ì—…ì˜ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
keywords = [
    'flutter',
    'python',
    'golang'
]

# keywordsì— ì €ì¥ëœ ê°¯ìˆ˜ë§Œí¼ ë°˜ë³µ
for i in range(len(keywords)):
    keyword=webScrap(keywords[i])  # 
    keyword.keywordJob()  # pageì˜ contentë¥¼ ì½ê¸°
    keyword.beautiSoup()  # ì½ì€ contentì—ì„œ ì›í•˜ëŠ” ì •ë³´ ì½ê¸° ì‹¤í–‰!
